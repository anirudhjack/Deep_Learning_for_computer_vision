{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfAofcZ4nYB1",
        "colab_type": "code",
        "outputId": "31f384f5-a25b-480b-c71e-fa81d4cecd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y17pB6Xltcz_",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Importing\\;neccesary\\;libraries\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL0Gj8CDtlLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random as rd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izhOdNdnPV5d",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Question\\;1(a):\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuVt-yn1u6yq",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Data\\;preprocessing\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYRYIh5Qt5gG",
        "colab_type": "code",
        "outputId": "ea52eb75-6bb7-4f34-dab0-6e9dd8f53708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir('/content/drive/My Drive/RNN')\n",
        "data = open('shakespeare_train.txt', 'r').read()\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 268330 characters, 62 unique.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zsx3AJ5vS0L",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Hyperparameters\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwaEQ6UDvMUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 50 # size of hidden layer of neurons\n",
        "seq_length = 25 # number of steps to unroll the RNN for\n",
        "learning_rate = 1e-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HREtsmpvblF",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Model\\;parameters\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLwJu7XZviW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model parameters\n",
        "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
        "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
        "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
        "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
        "by = np.zeros((vocab_size, 1)) # output bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEgVOhLKVHCR",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Function\\;for\\;reinitializing\\;the\\;parameters\\;of\\;RNN\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow4d3neAU465",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize(Wxh,Whh,Why,bh,by):\n",
        "  Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
        "  Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
        "  Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
        "  bh = np.zeros((hidden_size, 1)) # hidden bias\n",
        "  by = np.zeros((vocab_size, 1)) # output bias\n",
        "  return (Wxh,Whh,Why,bh,by)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5309TOoyREf",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Forward\\;Propagation\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlGWdb9NyQrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ForwardPropagate(x,h,z,y,a,inputs,targets,temperature):\n",
        "  loss = 0\n",
        "  for t in range(len(inputs)):\n",
        "    x[t] = np.zeros((vocab_size,1))                                                                                                                     \n",
        "    x[t][inputs[t]] = 1 \n",
        "    a[t]=np.dot(Wxh, x[t]) + np.dot(Whh, h[t-1]) + bh\n",
        "    h[t] = np.tanh(a[t])                                                                                                             \n",
        "    z[t] = np.dot(Why, h[t]) + by      \n",
        "    z[t] = (1/temperature)*z[t]                                                                                                      \n",
        "    y[t] = np.exp(z[t]) / np.sum(np.exp(z[t]))                                                                                                               \n",
        "    loss += -np.log(y[t][targets[t],0])\n",
        "  return x,h,z,y,a,loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB4KDJUNyiEi",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Back\\;propagation\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtvk3D5nymOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Backpropagate(y,targets,h,x,inputs,temperature):\n",
        "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
        "  dhnext = np.zeros_like(h[0])\n",
        "  for t in reversed(range(len(inputs))):\n",
        "    dz = np.copy(y[t])\n",
        "    dz[targets[t]] -= 1  \n",
        "    dz =(1/temperature)*dz\n",
        "    dWhy += np.dot(dz, h[t].T)\n",
        "    dby += dz\n",
        "    dh = np.dot(Why.T, dz) + dhnext                                                                                                                                          \n",
        "    da=dh*(1-np.square(h[t]))                                                                                                                      \n",
        "    dbh += da \n",
        "    dWxh += np.dot(da, x[t].T)\n",
        "    dWhh += np.dot(da, h[t-1].T)\n",
        "    dhnext = np.dot(Whh.T, da)\n",
        "\n",
        "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
        "  return dWxh,dWhh,dWhy,dbh,dby"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CesjMYUZDbcW",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Train\\;Function\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Sf8j_pz3xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Network(inputs, targets, hprev,temperature):\n",
        "  x, h, z, y, a,= {}, {}, {}, {},{} \n",
        "  h[-1] = np.copy(hprev)                                                                                                                                                                     \n",
        "  x,h,z,y,a,loss=ForwardPropagate(x,h,z,y,a,inputs,targets,temperature)\n",
        "  dWxh,dWhh,dWhy,dbh,dby=Backpropagate(y,targets,h,x,inputs,temperature)\n",
        "  return loss, dWxh, dWhh, dWhy, dbh, dby, h[len(inputs)-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsrSWtKDCkPu",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Sequence\\;generation\\;Function\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-AEnxoK2duv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(h, seed_ix, n,temperature):\n",
        "  \"\"\" \n",
        "  sample a sequence of integers from the model \n",
        "  h is memory state, seed_ix is seed letter for first time step\n",
        "  \"\"\"\n",
        "  x = np.zeros((vocab_size, 1))\n",
        "  x[seed_ix] = 1\n",
        "  ixes = []\n",
        "  for t in range(n):\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "    y = np.dot(Why, h) + by\n",
        "    y = (1/temperature)*y\n",
        "    p = np.exp(y) / np.sum(np.exp(y))\n",
        "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "    # ix =list(p).index(max(list(p)))\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[ix] = 1\n",
        "    ixes.append(ix)\n",
        "  return ixes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5RAIV3BrCtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(temperature,iterations):\n",
        "  n, p = 0, 0\n",
        "  mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "  mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
        "  smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
        "  while n<iterations:\n",
        "    # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
        "    if p+seq_length+1 >= len(data) or n == 0: \n",
        "      hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
        "      p = 0 # go from start of data\n",
        "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
        "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
        "\n",
        "    # sample from the model now and then\n",
        "    # if n % 100 == 0:\n",
        "    #   sample_ix = sample(hprev, inputs[0], 200)\n",
        "    #   txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "    #   print('----\\n %s \\n----' % (txt, ))\n",
        "\n",
        "    # forward seq_length characters through the net and fetch gradient\n",
        "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = Network(inputs, targets\n",
        "                                                      , hprev,temperature)\n",
        "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "    if n % 100 == 0:print ('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
        "    \n",
        "    # perform parameter update with Adagrad\n",
        "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
        "                                  [dWxh, dWhh, dWhy, dbh, dby], \n",
        "                                  [mWxh, mWhh, mWhy, mbh, mby]):\n",
        "      mem += dparam * dparam\n",
        "      param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
        "\n",
        "    p += seq_length # move data pointer\n",
        "    n += 1 # iteration counter "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEV-RKsxEUob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_RNN(test,hprev,temp):\n",
        "  sample_ix = sample(hprev, test[0], 200,temperature=temp)\n",
        "  txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "  print('----\\n %s \\n----' % (txt, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8cLJvMdW0LK",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Question\\;1:\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyD1W1lsDgkG",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Training\\;the\\;model\\;with\\;temperature=1\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyjMsBCRRxaJ",
        "colab_type": "code",
        "outputId": "4eb11349-4b93-496d-a8c7-ea75f5c6acba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "hidden_size=50\n",
        "(Wxh,Whh,Why,bh,by)=initialize(Wxh,Whh,Why,bh,by)\n",
        "train(\n",
        "    temperature=1,\n",
        "    iterations=5000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0, loss: 103.178369\n",
            "iter 100, loss: 101.683823\n",
            "iter 200, loss: 98.998454\n",
            "iter 300, loss: 95.824597\n",
            "iter 400, loss: 92.806532\n",
            "iter 500, loss: 89.996824\n",
            "iter 600, loss: 87.365605\n",
            "iter 700, loss: 85.120546\n",
            "iter 800, loss: 82.495669\n",
            "iter 900, loss: 80.219254\n",
            "iter 1000, loss: 78.246847\n",
            "iter 1100, loss: 76.133040\n",
            "iter 1200, loss: 74.340712\n",
            "iter 1300, loss: 72.743711\n",
            "iter 1400, loss: 71.385373\n",
            "iter 1500, loss: 69.914916\n",
            "iter 1600, loss: 68.683496\n",
            "iter 1700, loss: 67.431501\n",
            "iter 1800, loss: 66.465713\n",
            "iter 1900, loss: 65.326198\n",
            "iter 2000, loss: 64.418137\n",
            "iter 2100, loss: 63.666384\n",
            "iter 2200, loss: 62.627470\n",
            "iter 2300, loss: 61.989461\n",
            "iter 2400, loss: 61.020770\n",
            "iter 2500, loss: 60.202500\n",
            "iter 2600, loss: 59.582207\n",
            "iter 2700, loss: 58.975208\n",
            "iter 2800, loss: 58.000346\n",
            "iter 2900, loss: 57.592875\n",
            "iter 3000, loss: 57.202112\n",
            "iter 3100, loss: 56.700028\n",
            "iter 3200, loss: 56.156092\n",
            "iter 3300, loss: 55.788497\n",
            "iter 3400, loss: 55.251842\n",
            "iter 3500, loss: 54.891486\n",
            "iter 3600, loss: 54.790770\n",
            "iter 3700, loss: 54.407288\n",
            "iter 3800, loss: 54.001111\n",
            "iter 3900, loss: 53.954095\n",
            "iter 4000, loss: 53.626488\n",
            "iter 4100, loss: 53.363351\n",
            "iter 4200, loss: 53.378013\n",
            "iter 4300, loss: 52.997253\n",
            "iter 4400, loss: 53.004944\n",
            "iter 4500, loss: 53.011007\n",
            "iter 4600, loss: 52.856561\n",
            "iter 4700, loss: 52.758212\n",
            "iter 4800, loss: 52.595668\n",
            "iter 4900, loss: 52.583845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4lJH9OjWC1U",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Text\\;generated\\;at\\;Temperature\\;(1/\\alpha)=1\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn0OPTsgT3nP",
        "colab_type": "code",
        "outputId": "b3fbf2d6-ec45-43d8-e598-9bfd1992646e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test=[char_to_ix[ch] for ch in data[0:seq_length]]\n",
        "hprev = np.zeros((hidden_size,1))\n",
        "test_RNN(test,hprev,temp=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " ill and yut he seds; berede! he hoit totheld anst wearellC dfood.\n",
            "\n",
            "CORIOLANUS:\n",
            "The do prale the not- how surowellt; Ro hesso.\n",
            "\n",
            "LUENIUS:\n",
            "Wen haps on bracconftry arcoust you wher dve\n",
            "Mh ely?\n",
            "he shomll;  \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTaX_XtXD1U3",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Training\\;the\\;model\\;with\\;temperature=20\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylu2tFOvX8aj",
        "colab_type": "code",
        "outputId": "95c4b5d1-3fbe-4c00-f760-ee1b9649fa52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "hidden_size=50\n",
        "(Wxh,Whh,Why,bh,by)=initialize(Wxh,Whh,Why,bh,by)\n",
        "train(\n",
        "    temperature=20,\n",
        "    iterations=5000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0, loss: 103.178360\n",
            "iter 100, loss: 101.177080\n",
            "iter 200, loss: 99.226576\n",
            "iter 300, loss: 97.570612\n",
            "iter 400, loss: 95.942638\n",
            "iter 500, loss: 94.801438\n",
            "iter 600, loss: 93.342855\n",
            "iter 700, loss: 92.064238\n",
            "iter 800, loss: 90.803310\n",
            "iter 900, loss: 89.534179\n",
            "iter 1000, loss: 88.362052\n",
            "iter 1100, loss: 87.119615\n",
            "iter 1200, loss: 85.926893\n",
            "iter 1300, loss: 84.805078\n",
            "iter 1400, loss: 83.828153\n",
            "iter 1500, loss: 82.870611\n",
            "iter 1600, loss: 81.912088\n",
            "iter 1700, loss: 81.003943\n",
            "iter 1800, loss: 80.474359\n",
            "iter 1900, loss: 79.535894\n",
            "iter 2000, loss: 78.632422\n",
            "iter 2100, loss: 77.924552\n",
            "iter 2200, loss: 77.142219\n",
            "iter 2300, loss: 76.535100\n",
            "iter 2400, loss: 75.918893\n",
            "iter 2500, loss: 75.342182\n",
            "iter 2600, loss: 74.722640\n",
            "iter 2700, loss: 74.113616\n",
            "iter 2800, loss: 73.492291\n",
            "iter 2900, loss: 72.998451\n",
            "iter 3000, loss: 72.421025\n",
            "iter 3100, loss: 72.039584\n",
            "iter 3200, loss: 71.535000\n",
            "iter 3300, loss: 71.052536\n",
            "iter 3400, loss: 70.551121\n",
            "iter 3500, loss: 70.092119\n",
            "iter 3600, loss: 69.780031\n",
            "iter 3700, loss: 69.359713\n",
            "iter 3800, loss: 68.970120\n",
            "iter 3900, loss: 68.731228\n",
            "iter 4000, loss: 68.289057\n",
            "iter 4100, loss: 67.993687\n",
            "iter 4200, loss: 67.772990\n",
            "iter 4300, loss: 67.576841\n",
            "iter 4400, loss: 67.350602\n",
            "iter 4500, loss: 67.214144\n",
            "iter 4600, loss: 67.049677\n",
            "iter 4700, loss: 66.796744\n",
            "iter 4800, loss: 66.512072\n",
            "iter 4900, loss: 66.358232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLXsP9pEEjUi",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Text\\;Generation\\;at\\;temperature=20\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl-pXnQPYEYh",
        "colab_type": "code",
        "outputId": "40facd38-e7d6-427f-d8e7-ffef776cca9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "test=[char_to_ix[ch] for ch in data[0:seq_length]]\n",
        "hprev = np.zeros((hidden_size,1))\n",
        "test_RNN(test,hprev,temp=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "  be\n",
            "Iet in nor,\n",
            "th tine denum mal, nanake soewm\n",
            "eotoer jesret veerdry saSnisseav.\n",
            "\n",
            "IMUMLAOUURS\n",
            ":UI:\n",
            "\n",
            "NaIA\n",
            "ONCNUUO&US:?:\n",
            "A, wiee moanf ItiAom idgnamd taullteem, Whau sleen terees' py bhos noaa,r-gatyl, \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b10Xj4hEr9s",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Training\\;the\\;model\\;at\\;temperature=0.5\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOTqf4Yqbbw7",
        "colab_type": "code",
        "outputId": "3d3d21b0-ad8c-40ba-8278-5e4de233aa66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "hidden_size=50\n",
        "(Wxh,Whh,Why,bh,by)=initialize(Wxh,Whh,Why,bh,by)\n",
        "train(\n",
        "    temperature=0.5,\n",
        "    iterations=5000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0, loss: 103.178368\n",
            "iter 100, loss: 103.170514\n",
            "iter 200, loss: 100.348789\n",
            "iter 300, loss: 96.894320\n",
            "iter 400, loss: 93.692754\n",
            "iter 500, loss: 90.740584\n",
            "iter 600, loss: 87.960935\n",
            "iter 700, loss: 85.613626\n",
            "iter 800, loss: 82.778802\n",
            "iter 900, loss: 80.338325\n",
            "iter 1000, loss: 78.308970\n",
            "iter 1100, loss: 76.090927\n",
            "iter 1200, loss: 74.233372\n",
            "iter 1300, loss: 72.564992\n",
            "iter 1400, loss: 71.131357\n",
            "iter 1500, loss: 69.496593\n",
            "iter 1600, loss: 68.222658\n",
            "iter 1700, loss: 66.859533\n",
            "iter 1800, loss: 65.825738\n",
            "iter 1900, loss: 64.543633\n",
            "iter 2000, loss: 63.566783\n",
            "iter 2100, loss: 62.770639\n",
            "iter 2200, loss: 61.597421\n",
            "iter 2300, loss: 60.915302\n",
            "iter 2400, loss: 59.808740\n",
            "iter 2500, loss: 58.840202\n",
            "iter 2600, loss: 58.194281\n",
            "iter 2700, loss: 57.597277\n",
            "iter 2800, loss: 56.577175\n",
            "iter 2900, loss: 56.185706\n",
            "iter 3000, loss: 55.822228\n",
            "iter 3100, loss: 55.212233\n",
            "iter 3200, loss: 54.616635\n",
            "iter 3300, loss: 54.308595\n",
            "iter 3400, loss: 53.789723\n",
            "iter 3500, loss: 53.432018\n",
            "iter 3600, loss: 53.330749\n",
            "iter 3700, loss: 52.950938\n",
            "iter 3800, loss: 52.555813\n",
            "iter 3900, loss: 52.528986\n",
            "iter 4000, loss: 52.218000\n",
            "iter 4100, loss: 51.948823\n",
            "iter 4200, loss: 51.958729\n",
            "iter 4300, loss: 51.441396\n",
            "iter 4400, loss: 51.465861\n",
            "iter 4500, loss: 51.413028\n",
            "iter 4600, loss: 51.151985\n",
            "iter 4700, loss: 51.110643\n",
            "iter 4800, loss: 50.941754\n",
            "iter 4900, loss: 50.918584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xr2j-l-FMct",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Text\\;generation\\;at\\;temperature=0.5\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aubHJN99E-Kh",
        "colab_type": "code",
        "outputId": "409ae0ba-bfc8-4832-90c9-add7c97d1cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "test=[char_to_ix[ch] for ch in data[0:seq_length]]\n",
        "hprev = np.zeros((hidden_size,1))\n",
        "test_RNN(test,hprev,temp=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " in tish to kef an ion your This she verall. I to alt es com, liny; not thes bray my nore wat shas arts nod the ande thom lle t aicr, oples,\n",
            "Ast stond mwets lavers. I pores\n",
            "youre\n",
            "To V py?\n",
            "Aglasthe cose \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJBtL5t0FhJR",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Observations:At\\;low\\;temperature\\;the\\;model\\;converges\\;fast\\;comapred\\;to\\;model\\;with\\;high\\;temperature.\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAzAoz4bkSPT",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Question\\;2:String\\;Completion\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb0xsu5M2Ecv",
        "colab_type": "code",
        "outputId": "7d284de0-8069-4730-e7a8-44a105c0ee5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#sentence for completion:\n",
        "String=data[15:60]\n",
        "print(String)\n",
        "print('Actual Sentence:')\n",
        "print('------')\n",
        "print(data[15:261])\n",
        "print('------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before we proceed any further, hear me speak.\n",
            "Actual Sentence:\n",
            "------\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We kn\n",
            "------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q__d6jemHWU",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Loading\\;the\\;weights\\;of\\;trained\\;RNN\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wQ6aeFoFZuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size=250\n",
        "(Wxh,Whh,Why,bh,by)=initialize(Wxh,Whh,Why,bh,by)\n",
        "with open(\"char-rnn-snapshot.pkl\", 'rb') as f:\n",
        "    u = pickle._Unpickler(f)\n",
        "    u.encoding = 'latin1'\n",
        "    a = u.load()\n",
        "# a = pickle.load(open(\"char-rnn-snapshot.pkl\",'rb'))\n",
        "Wxh = a[\"Wxh\"] \n",
        "Whh = a[\"Whh\"]\n",
        "Why = a[\"Why\"]\n",
        "bh = a[\"bh\"]\n",
        "by = a[\"by\"]\n",
        "mWxh, mWhh, mWhy = a[\"mWxh\"], a[\"mWhh\"], a[\"mWhy\"]\n",
        "mbh, mby = a[\"mbh\"], a[\"mby\"]\n",
        "chars, data_size= a[\"chars\"].tolist(), a[\"data_size\"].tolist()\n",
        "vocab_size, char_to_ix = a[\"vocab_size\"].tolist(), a[\"char_to_ix\"].tolist() \n",
        "ix_to_char =  a[\"ix_to_char\"].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9nupxl6JL7l",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Function\\;for\\;Calculating\\;hidden\\;state\\;at\\;the\\;end\\;of\\;the\\;sentence.\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_VfOWK_1bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hidden_state(h,sentence):\n",
        "  x = np.zeros((vocab_size, 1))\n",
        "  x[sentence[0]] = 1\n",
        "  ixes = []\n",
        "  for t in range(1,len(sentence)-1):\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "    ix = sentence[t]\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[ix] = 1\n",
        "    ixes.append(ix)\n",
        "  return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efvlXzhoJaUd",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Completing\\;the\\;string\\;using\\;RNN\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3dz4AWl3z7s",
        "colab_type": "code",
        "outputId": "d40d9aad-3ab9-49bb-e5b3-7b29e58b8b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test=[char_to_ix[ch] for ch in String]\n",
        "print('String for Completion:')\n",
        "print(String)\n",
        "for i in range(5):\n",
        "  print(' %dth Generated String:'%(i+1))\n",
        "  hprev = np.zeros((hidden_size,1))\n",
        "  hidden_st= hidden_state(h=hprev,sentence=test)\n",
        "  sample_ix = sample(hidden_st,test[-1], 200,temperature=1)\n",
        "  txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "  print('----\\n %s \\n----' % (txt, ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "String for Completion:\n",
            "Before we proceed any further, hear me speak.\n",
            " 1th Generated String:\n",
            "----\n",
            " \n",
            "\n",
            "CORIOLANUS:\n",
            "To wast lesch bove them ix not fel: suven, to in the with\n",
            "Ane pound What parch way, we of be that have\n",
            "A'\n",
            "Onl lel aceing; solf'd deap, passen speatssent now thet puon's anf I well lorgel \n",
            "----\n",
            " 2th Generated String:\n",
            "----\n",
            " \n",
            "To tell pooble mo I flems!\n",
            "\n",
            "MENENIUS:\n",
            "I'lf for put for 'Tis my sovere, we do then! move-ined cits:\n",
            "And what?\n",
            "\n",
            "BRUTUS:\n",
            "Which he the you:\n",
            "Wereizense yim;\n",
            "Farse.\n",
            "As com love coan.\n",
            "\n",
            "VOLUMNIA:\n",
            "O'll thy th \n",
            "----\n",
            " 3th Generated String:\n",
            "----\n",
            " \n",
            "\n",
            "SICINIUS:\n",
            "Jovon do im;\n",
            "Who ammion, lature mofurus he. Haged arpe, I'll him be ean,\n",
            "I befoot hadge some.\n",
            "\n",
            "COMINIUS:\n",
            "For wis!\n",
            "\n",
            "VALERIS:\n",
            "When moves, my porsm lord for as hus whatter Buthon I Catay the  \n",
            "----\n",
            " 4th Generated String:\n",
            "----\n",
            "  From mo logst\n",
            "Sonfellowe, go,\n",
            "Oacon's:\n",
            "And wood.\n",
            "\n",
            "VOLUMNIA:\n",
            "Fnafore,\n",
            "A's pore you one whre's\n",
            "'pees\n",
            "Be and brack sadrelt whomt onrers sivetute,\n",
            "Butind Rombmeds :\n",
            "Wy coms in fon.\n",
            "Wildes in call thou lo \n",
            "----\n",
            " 5th Generated String:\n",
            "----\n",
            " \n",
            "\n",
            "SICINIUS:\n",
            "Seate,\n",
            "Cat you no thy herband untolf, sirs ab ace a had my his\n",
            "Weach on the you, moar: hilair,\n",
            "stluingen scounts: behespan:\n",
            "If do winoury are fon be's in holy nere gis time it tow, be we d \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPpLW8OlkpGp",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Question\\;3:Reason\\;for\\;newlines\\;or\\;spaces\\;after\\;colon(:)\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iFw9imyfLkS",
        "colab_type": "code",
        "outputId": "7595a9cd-f695-4c1d-d7bf-2757d815bd8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Index of semi colon is %d'%char_to_ix[':'])\n",
        "print('Index of new line is %d'%char_to_ix['\\n'])\n",
        "print('Index of space is %d'%char_to_ix[' '])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of semi colon is 9\n",
            "Index of new line is 0\n",
            "Index of space is 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC_f3J4j6vSX",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Visualize\\;weight\\;matrices\\;when\\;input\\;is\\;semicolon(:)\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vvyOaSi6u0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check(h, seed_ix, n,temperature,character1,character2):\n",
        "  x = np.zeros((vocab_size, 1))\n",
        "  x[seed_ix] = 1\n",
        "  ixes = []\n",
        "  for t in range(n):\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
        "    if x[char_to_ix[character1]]==1:\n",
        "      indic=list()\n",
        "      for i in range(len(h)):\n",
        "        if((h[i]>0 and Why[char_to_ix[character2]][i]>0)or(h[i]<0 and Why[char_to_ix[character2]][i]<0)):\n",
        "          cord=list()\n",
        "          cord.append(char_to_ix[character2])\n",
        "          cord.append(i)\n",
        "          indic.append(cord)\n",
        "      print('The cordinates of Why which are responsible:')\n",
        "      print(indic)\n",
        "    y = np.dot(Why, h) + by\n",
        "    y = (1/temperature)*y\n",
        "    p = np.exp(y) / np.sum(np.exp(y))\n",
        "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "    # ix =list(p).index(max(list(p)))\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[ix] = 1\n",
        "    ixes.append(ix)\n",
        "  return ixes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmOwQYH6d0UP",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Finding\\;the\\;indices\\;of\\;specific\\;hidden\\;neurons\\;which\\;fire\\;when\\;':'\\;is\\;given\\;as\\;input.\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCTfBcfiGjcC",
        "colab_type": "code",
        "outputId": "2d999b37-7662-4943-fe00-d9c30f779361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "hidden_st1=np.zeros((hidden_size,1))\n",
        "sample_ix = check(hidden_st1\n",
        "                  ,char_to_ix[':']\n",
        "                  , n=200\n",
        "                  ,temperature=1\n",
        "                  ,character1=':'\n",
        "                  ,character2='\\n')\n",
        "txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "print('----\\n %s \\n----' % (txt, ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 5], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 14], [0, 15], [0, 16], [0, 17], [0, 18], [0, 19], [0, 20], [0, 23], [0, 24], [0, 25], [0, 26], [0, 27], [0, 28], [0, 29], [0, 31], [0, 32], [0, 33], [0, 34], [0, 35], [0, 36], [0, 37], [0, 39], [0, 40], [0, 42], [0, 44], [0, 46], [0, 51], [0, 52], [0, 53], [0, 54], [0, 55], [0, 59], [0, 60], [0, 62], [0, 63], [0, 64], [0, 65], [0, 67], [0, 68], [0, 70], [0, 72], [0, 73], [0, 75], [0, 76], [0, 77], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 95], [0, 96], [0, 97], [0, 99], [0, 100], [0, 102], [0, 103], [0, 106], [0, 108], [0, 109], [0, 110], [0, 111], [0, 113], [0, 114], [0, 116], [0, 118], [0, 120], [0, 123], [0, 124], [0, 125], [0, 126], [0, 128], [0, 129], [0, 131], [0, 132], [0, 133], [0, 137], [0, 138], [0, 139], [0, 141], [0, 142], [0, 143], [0, 144], [0, 145], [0, 146], [0, 147], [0, 149], [0, 152], [0, 155], [0, 156], [0, 158], [0, 159], [0, 162], [0, 167], [0, 169], [0, 170], [0, 171], [0, 172], [0, 173], [0, 175], [0, 177], [0, 178], [0, 181], [0, 182], [0, 183], [0, 185], [0, 186], [0, 187], [0, 188], [0, 191], [0, 192], [0, 193], [0, 196], [0, 197], [0, 199], [0, 200], [0, 202], [0, 205], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 215], [0, 217], [0, 218], [0, 219], [0, 221], [0, 223], [0, 224], [0, 228], [0, 230], [0, 237], [0, 238], [0, 239], [0, 240], [0, 241], [0, 242], [0, 245], [0, 249]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 44], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 63], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 95], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 114], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 134], [0, 135], [0, 136], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 159], [0, 160], [0, 161], [0, 162], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 185], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 226], [0, 228], [0, 230], [0, 231], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 43], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 114], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 134], [0, 135], [0, 136], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 160], [0, 161], [0, 162], [0, 166], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 226], [0, 228], [0, 230], [0, 231], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 44], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 63], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 95], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 114], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 135], [0, 136], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 159], [0, 160], [0, 161], [0, 162], [0, 166], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 185], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 226], [0, 228], [0, 230], [0, 231], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "----\n",
            " \n",
            "\n",
            "lESTARDERT:\n",
            "With honse kincy that me of what be wimo.\n",
            "Who proulf to, hath so, for no hearney, the not a qu! fan an the spake Comher:\n",
            "lish had anvind, warch?\n",
            "\n",
            "SICINIUS:\n",
            "My sufe ghe the for the carven \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "279CRcNx2YIT",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Explanation:We\\;give\\;the\\;input\\;to\\;the\\;RNN\\;specific\\;neurons\\;fire\\;which\\;produce\\;newline.Specific\\;weights\\;of\\;Why\\;which\\;are\\;connected\\;to\\;the\\;index\\;of\\;newline\\;output\\;are\\;responsible\\;for\\;the\\;behaviour.\n",
        "\\\\\\implies Specific\n",
        "\\;weights\\;are\\;Why[index][index1]*h[index1]>0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtfyIpPaxzK6",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Question\\;4:Another\\;behaviour:\n",
        "\\\\newline\\;after\\;letter\\;'.'\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja1VGezw2VTS",
        "colab_type": "code",
        "outputId": "d76cf0c2-94bd-4d43-ba93-a14fd16600d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "hidden_st1=np.zeros((hidden_size,1))\n",
        "sample_ix = check(hidden_st1\n",
        "                  ,char_to_ix['.']\n",
        "                  , n=200\n",
        "                  ,temperature=1\n",
        "                  ,character1='.'\n",
        "                  ,character2='\\n')\n",
        "txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "print('----\\n %s \\n----' % (txt, ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 1], [0, 3], [0, 5], [0, 7], [0, 8], [0, 9], [0, 11], [0, 12], [0, 14], [0, 16], [0, 17], [0, 18], [0, 19], [0, 20], [0, 24], [0, 25], [0, 26], [0, 27], [0, 28], [0, 29], [0, 31], [0, 32], [0, 33], [0, 34], [0, 35], [0, 37], [0, 39], [0, 40], [0, 41], [0, 42], [0, 43], [0, 45], [0, 46], [0, 47], [0, 49], [0, 52], [0, 53], [0, 54], [0, 55], [0, 56], [0, 59], [0, 60], [0, 63], [0, 64], [0, 65], [0, 66], [0, 67], [0, 68], [0, 72], [0, 73], [0, 74], [0, 76], [0, 77], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 86], [0, 87], [0, 89], [0, 90], [0, 91], [0, 92], [0, 95], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 106], [0, 107], [0, 109], [0, 110], [0, 111], [0, 113], [0, 115], [0, 116], [0, 118], [0, 122], [0, 124], [0, 125], [0, 128], [0, 129], [0, 131], [0, 132], [0, 134], [0, 137], [0, 138], [0, 139], [0, 140], [0, 141], [0, 143], [0, 144], [0, 145], [0, 146], [0, 147], [0, 149], [0, 152], [0, 155], [0, 156], [0, 158], [0, 159], [0, 161], [0, 162], [0, 166], [0, 167], [0, 168], [0, 169], [0, 170], [0, 172], [0, 173], [0, 174], [0, 175], [0, 176], [0, 177], [0, 178], [0, 181], [0, 182], [0, 183], [0, 186], [0, 187], [0, 191], [0, 192], [0, 193], [0, 194], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 205], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 214], [0, 215], [0, 216], [0, 218], [0, 219], [0, 221], [0, 223], [0, 225], [0, 226], [0, 228], [0, 230], [0, 232], [0, 234], [0, 237], [0, 238], [0, 240], [0, 242], [0, 245], [0, 249]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 3], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 43], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 63], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 134], [0, 135], [0, 136], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 159], [0, 160], [0, 161], [0, 162], [0, 166], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 225], [0, 226], [0, 228], [0, 230], [0, 231], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 3], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 43], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 63], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 134], [0, 135], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 159], [0, 160], [0, 161], [0, 162], [0, 166], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 225], [0, 226], [0, 228], [0, 230], [0, 231], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 3], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 43], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 63], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 134], [0, 135], [0, 136], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 160], [0, 161], [0, 162], [0, 166], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 226], [0, 228], [0, 230], [0, 231], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "The cordinates of Why which are responsible:\n",
            "[[0, 0], [0, 2], [0, 3], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 13], [0, 14], [0, 16], [0, 18], [0, 19], [0, 22], [0, 23], [0, 24], [0, 25], [0, 27], [0, 29], [0, 30], [0, 31], [0, 32], [0, 33], [0, 35], [0, 36], [0, 37], [0, 38], [0, 39], [0, 40], [0, 41], [0, 43], [0, 46], [0, 47], [0, 49], [0, 51], [0, 52], [0, 53], [0, 56], [0, 59], [0, 60], [0, 61], [0, 62], [0, 63], [0, 64], [0, 66], [0, 68], [0, 69], [0, 71], [0, 72], [0, 73], [0, 76], [0, 78], [0, 79], [0, 80], [0, 81], [0, 82], [0, 84], [0, 85], [0, 86], [0, 87], [0, 88], [0, 89], [0, 90], [0, 91], [0, 92], [0, 94], [0, 96], [0, 97], [0, 99], [0, 100], [0, 101], [0, 102], [0, 103], [0, 105], [0, 106], [0, 107], [0, 108], [0, 109], [0, 110], [0, 112], [0, 113], [0, 116], [0, 117], [0, 118], [0, 122], [0, 123], [0, 124], [0, 125], [0, 126], [0, 127], [0, 128], [0, 129], [0, 132], [0, 134], [0, 135], [0, 136], [0, 137], [0, 139], [0, 141], [0, 142], [0, 143], [0, 145], [0, 149], [0, 150], [0, 151], [0, 152], [0, 153], [0, 154], [0, 155], [0, 156], [0, 157], [0, 159], [0, 160], [0, 161], [0, 162], [0, 166], [0, 168], [0, 169], [0, 170], [0, 171], [0, 172], [0, 175], [0, 176], [0, 178], [0, 179], [0, 182], [0, 186], [0, 187], [0, 189], [0, 190], [0, 191], [0, 193], [0, 194], [0, 195], [0, 196], [0, 197], [0, 199], [0, 200], [0, 203], [0, 204], [0, 206], [0, 207], [0, 208], [0, 209], [0, 210], [0, 212], [0, 213], [0, 215], [0, 216], [0, 217], [0, 218], [0, 220], [0, 222], [0, 223], [0, 225], [0, 226], [0, 228], [0, 230], [0, 231], [0, 234], [0, 237], [0, 238], [0, 240], [0, 241], [0, 242], [0, 244], [0, 246]]\n",
            "----\n",
            " \n",
            "Nex what ghanout,\n",
            "\n",
            "BRIUS:\n",
            "What\n",
            "of, He joy, and hads.--\n",
            " in the thy nain.\n",
            "\n",
            "Firshy was, he.\n",
            "\n",
            "CORIOLANUS:\n",
            "Sirces.\n",
            "\n",
            "BRUTUS:\n",
            "If they sives; well he to be imed how'st?,\n",
            "Bo sives our his as An back?\n",
            "\n",
            "VOLUMN \n",
            "----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMrwu1LO4Ywf",
        "colab_type": "text"
      },
      "source": [
        "$\n",
        "Explanation:We\\;give\\;the\\;input\\;to\\;the\\;RNN\\;specific\\;neurons\\;fire\\;which\\;produce\\;newline.Specific\\;weights\\;of\\;Why\\;which\\;are\\;connected\\;to\\;the\\;index\\;of\\;newline\\;output\\;are\\;responsible\\;for\\;the\\;behaviour.\n",
        "\\\\\\implies Specific\n",
        "\\;weights\\;are\\;Why[index][index1]*h[index1]>0$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LDhHsN55ZNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}