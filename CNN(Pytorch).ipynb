{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN(Pytorch).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCzRcaA3SRPp",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "\\\\\\textbf{Question 4:}\n",
        "\\\\Convolutional\\;neural\\;networks\\;on\\;MNIST\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npvc3TPoqsqL",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Importing\\;the\\;neccessary\\;libraries:\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C1i-cR9Q558",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from easydict import EasyDict as edict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ws3AD0Xqyxf",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Function\\;for\\;CNN\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSWNqcz-Q_hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebnFBcTsq5VS",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Function\\;training\\;CNN\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ZJ1AKgRT9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss=0\n",
        "    correct=0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.argmax(dim=1, keepdim=True) \n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()  \n",
        "        \n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    print('Train Epoch {:.0f}\\n Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(epoch,\n",
        "        train_loss, correct, len(train_loader.dataset),\n",
        "        100. * correct / len(train_loader.dataset)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAspdITcrALW",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Function\\;for\\;testing\\;CNN\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRmQhkvkRcdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() \n",
        "            pred = output.argmax(dim=1, keepdim=True) \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bltvG2srEpx",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Main\\;function\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiqPIxlGRhzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_eval(Model,batch_size,test_batch_size,epochs,learning_rate,momentum):\n",
        "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
        "    \n",
        "    args = edict({\n",
        "    \"batch_size\": batch_size,\n",
        "    \"test_batch_size\": test_batch_size,\n",
        "    \"epochs\":epochs,\n",
        "    \"lr\":learning_rate,\n",
        "    \"momentum\":momentum,\n",
        "    \"no_cuda\":False,\n",
        "    \"seed\":1,\n",
        "    \"log_interval\":10,\n",
        "    \"save_model\":False\n",
        "    })\n",
        "    \n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "    model = Model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters()\n",
        "                          , lr=args.lr, momentum=args.momentum)\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train(args, model, device, train_loader, optimizer, epoch)\n",
        "        test(args, model, device, test_loader)\n",
        "\n",
        "    if (args.save_model):\n",
        "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqyB-tGcltRP",
        "colab_type": "code",
        "outputId": "94731cc3-d0bf-49f9-a7ee-14f770a88339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "train_eval(Net()\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1\n",
            " Train set: Average loss: 0.3378, Accuracy: 54154/60000 (90.2567%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1169, Accuracy: 9627/10000 (96.2700%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.0871, Accuracy: 58399/60000 (97.3317%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0613, Accuracy: 9811/10000 (98.1100%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC9evwgOxmAV",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Question\\;4(a):\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izh4iZVsxlEO",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Replacing\\;RELUs\\;with\\;sigmoids\\;in\\;initial\\;layers\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZjw5-cHmXWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.sigmoid(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM85wym9wped",
        "colab_type": "code",
        "outputId": "0b1af820-1288-4ab7-f0cd-8eb9fafaf57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "train_eval(Net1()\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1\n",
            " Train set: Average loss: 2.1679, Accuracy: 15845/60000 (26.4083%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 1.4271, Accuracy: 6776/10000 (67.7600%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.6720, Accuracy: 49172/60000 (81.9533%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.4156, Accuracy: 8799/10000 (87.9900%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC9e7H6FyUjL",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Obeservations:The\\;network\\;trained\\;with\\;Relu\\;layers\\;performing\\;better\\;compared\\;sigmoid\\;layers\\;in\\;same\\;number\\;of\\;epochs\n",
        "\\\\\\implies This\\;because\\;gradients\\;backpropagated\\;by\\;sigmoid\\;layers\\;are\\;very\\;less\\;compared\\;to\\;relu\\;layers\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6xYiIJMxdhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self,p):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        self.Dropout=torch.nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.Dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4UfdQSj0Fai",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Training\\;different\\;CNNs\\;with\\;different\\;dropouts(0.25,0.5,0.75,1)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99XdupIIzutN",
        "colab_type": "code",
        "outputId": "d5d75018-a908-4a11-8f7e-3b59687e0ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "print(\"CNN with dropout 0.25\")\n",
        "train_eval(Net2(0.25)\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)\n",
        "print(\"CNN with dropout 0.5\")\n",
        "train_eval(Net2(0.5)\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)\n",
        "print(\"CNN with dropout 0.75\")\n",
        "train_eval(Net2(0.75)\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)\n",
        "print(\"CNN with dropout 1\")\n",
        "train_eval(Net2(1)\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN with dropout 0.25\n",
            "Train Epoch 1\n",
            " Train set: Average loss: 0.3592, Accuracy: 53566/60000 (89.2767%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1139, Accuracy: 9639/10000 (96.3900%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.0991, Accuracy: 58205/60000 (97.0083%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0668, Accuracy: 9794/10000 (97.9400%)\n",
            "\n",
            "CNN with dropout 0.5\n",
            "Train Epoch 1\n",
            " Train set: Average loss: 0.3801, Accuracy: 53076/60000 (88.4600%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1009, Accuracy: 9674/10000 (96.7400%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.1093, Accuracy: 58032/60000 (96.7200%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0596, Accuracy: 9806/10000 (98.0600%)\n",
            "\n",
            "CNN with dropout 0.75\n",
            "Train Epoch 1\n",
            " Train set: Average loss: 0.4582, Accuracy: 51318/60000 (85.5300%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1041, Accuracy: 9667/10000 (96.6700%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.1444, Accuracy: 57388/60000 (95.6467%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0651, Accuracy: 9798/10000 (97.9800%)\n",
            "\n",
            "CNN with dropout 1\n",
            "Train Epoch 1\n",
            " Train set: Average loss: 2.3017, Accuracy: 6640/60000 (11.0667%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 2.2988, Accuracy: 1165/10000 (11.6500%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 2.3013, Accuracy: 6742/60000 (11.2367%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 2.2987, Accuracy: 1164/10000 (11.6400%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNnn59bwSfll",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Observations:The\\;network\\;with\\;dropouts=0.25,0.5\\;acheived\\;better\\;accuracy\\;compared\\;to\\;networks\\;with\\;dropouts=0.75,1\n",
        "\\\\\\implies The\\;network\\;with\\;dropout=1\\;is\\;predicting\\;random\\;labels\\;because\\;gradients\\;haven't\\;backpropagated\\;to\\;the\\;convolutional\\;layers\\;and\\;network\\;is\\;not\\;trained.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwZOaNiQ4GNC",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Question\\;4(c):\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q51z8HPD4LkP",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Adding\\;batch\\;normalization\\;layer\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbiYICkW02Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net3(nn.Module):\n",
        "    def __init__(self,p):\n",
        "        super(Net3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv1_bn = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(50)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        self.Dropout=torch.nn.Dropout(p)\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv1_bn(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2_bn(x)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.Dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztc_RCe26Dzd",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Training\\;a\\;CNN\\;with\\;Dropout=0.5\\;including\\;Batch\\;normalization\\;layer\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfWJRdbp5zFC",
        "colab_type": "code",
        "outputId": "87119c94-faa8-483f-9e55-d7a503fffb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "train_eval(Net3(0.5)\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1\n",
            " Train set: Average loss: 0.2251, Accuracy: 56461/60000 (94.1017%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0588, Accuracy: 9823/10000 (98.2300%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.0679, Accuracy: 58815/60000 (98.0250%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0425, Accuracy: 9860/10000 (98.6000%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYQcYV3wUc71",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Observations:The\\;model\\;is\\;acheiving\\;better\\;accuracy\\;when\\;we\\;add\\;batch\\;normalization\\;layers\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWYxUJDI7jUp",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Above\\;Network\\;after\\;removing\\;Dropout\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keTj7qc652e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net4(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(Net4, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv1_bn = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(50)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv1_bn(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2_bn(x)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWYfYkdU8DEk",
        "colab_type": "code",
        "outputId": "d3dbeb71-e6bc-4247-ce04-85b1a330471b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "train_eval(Net4()\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1\n",
            " Train set: Average loss: 0.1927, Accuracy: 57219/60000 (95.3650%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0602, Accuracy: 9818/10000 (98.1800%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.0542, Accuracy: 59073/60000 (98.4550%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0466, Accuracy: 9861/10000 (98.6100%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbJqqWUbU0Y_",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Observations:There\\;is\\;no\\;considerable\\;change\\;in\\;accuracy\\;if\\;we\\;remove\\;dropout\\;from\\;the\\;network\\;with\\;batchnormalization\\;layers\n",
        "\\\\\\implies We\\;don't\\;need\\;dropout\\;if\\;the\\;network\\;has\\;batch\\;normalization\\;layers\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl3n4sJ09KkO",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Initializing\\;the\\;CNN\\;weights\\;using\\;xavier\\;initialization:\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQfEfvoc8Kt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net5(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(Net5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
        "        self.conv1_bn = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
        "        self.conv2_bn = nn.BatchNorm2d(50)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv1_bn(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2_bn(x)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR7ZwUQr-O8D",
        "colab_type": "code",
        "outputId": "d25c09d0-6641-4618-d4ea-e270eab15c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "train_eval(Net5()\n",
        "          ,batch_size=64\n",
        "          ,test_batch_size=1000\n",
        "           ,epochs=2\n",
        "           ,learning_rate=0.01\n",
        "           ,momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 1\n",
            " Train set: Average loss: 0.1254, Accuracy: 57878/60000 (96.4633%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0540, Accuracy: 9839/10000 (98.3900%)\n",
            "\n",
            "Train Epoch 2\n",
            " Train set: Average loss: 0.0443, Accuracy: 59243/60000 (98.7383%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0437, Accuracy: 9855/10000 (98.5500%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9t9761o_mmx",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "Observations:The\\;Accuracy\\;on\\;network\\;with\\;batch\\;normalization\\;layers\\;haven't\\;changed\\;with\\;different\\;weight\\;initializations.\n",
        "\\\\\\implies Different\\;weight\\;initializations\\;dont\\;effect\\;the\\;performance\\;of\\;the\\;network\\;with\\;batch\\;normalizations.\n",
        "\\\\\\implies Because\\;the\\;batch\\;normalization\\;layers\\;achieve\\;optimal\\;mean\\;and\\;varaince\\;of\\;the\\;layers\\;activations\\;irrespective\\;of\\;weight\\;initializations\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJYRWpBI-UY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}